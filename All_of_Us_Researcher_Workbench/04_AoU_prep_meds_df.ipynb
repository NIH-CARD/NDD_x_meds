{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select your NDD and the date\n",
    "ndd = 'DEM'\n",
    "date = 'MAY_05_2025'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the NDD case files created in step 01\n",
    "#cases = pd.read_csv('AD_cases_n666.csv')\n",
    "#cases = pd.read_csv(f'PD_cases_n1713.csv')\n",
    "cases = pd.read_csv('DEM_cases_n2825.csv')\n",
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to match my code\n",
    "cases = cases.rename(columns = {'person_id':'ID', f'{ndd}_date':f'{ndd}_DATE'}) \n",
    "cases = cases[['ID', 'date_of_birth', 'sex_at_birth', f'{ndd}_DATE']]\n",
    "cases = cases.sort_values(by = f'{ndd}_DATE')\n",
    "cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load controls created in step 02\n",
    "controls = pd.read_csv('controls_60_n135891.csv')\n",
    "controls[f'{ndd}_DATE'] = np.nan\n",
    "controls = controls.rename(columns = {'person_id':'ID'}) \n",
    "controls = controls[['ID', 'date_of_birth', 'sex_at_birth', f'{ndd}_DATE']]\n",
    "controls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine cases and controls\n",
    "df = pd.concat([cases, controls])\n",
    "\n",
    "#Check to make sure no duplicate IDs\n",
    "print(df.ID.value_counts())\n",
    "\n",
    "df = df.sort_values(by = f'{ndd}_DATE')\n",
    "df = df.drop_duplicates(subset = 'ID', keep = 'first')\n",
    "\n",
    "#Check to make sure no duplicate IDs\n",
    "print(df.ID.value_counts())\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add DEATH YEAR from file created in step 02\n",
    "d = pd.read_csv('death_date.csv')\n",
    "d = d.rename(columns = {'person_id':'ID', 'death_date':'DATE_OF_DEATH'})\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with cases/controls\n",
    "df = df.merge(d, left_on = 'ID', right_on = 'ID', how = 'left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add recruit year from file created in step 02\n",
    "r = pd.read_csv('primary_consent_date.csv')\n",
    "r = r.rename(columns = {'person_id':'ID', 'primary_consent_date':'recruit_date'})\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge with cases/controls\n",
    "df = df.merge(r, left_on = 'ID', right_on = 'ID', how = 'left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# people with drug exposure data from file created in step 02\n",
    "de = pd.read_csv('people_with_drug_data.csv')\n",
    "de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of people who have drug data available\n",
    "people_list = list(de['person_id'])\n",
    "print(len(people_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only keep people who have drug data available\n",
    "df = df[df['ID'].isin(people_list)]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check for NAs\n",
    "print('Sex:', df.sex_at_birth.isna().value_counts())\n",
    "print('Birth year:', df.date_of_birth.isna().value_counts())\n",
    "#print('AGE:', df.AGE_OF_RECRUIT.isna().value_counts())\n",
    "print('recruit date:', df.recruit_date.isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check number of cases and controls\n",
    "df[f'{ndd}_DATE'].isna().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add drug codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meds2 = pd.read_csv('meds_with_cleaned_name_MAY_05_2025.csv')\n",
    "list_drugs = list(set(list(meds2['cleaned_med'])))\n",
    "print(len(list_drugs))\n",
    "meds2.cleaned_med.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_bucket = os.getenv('WORKSPACE_BUCKET')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of drug csv\n",
    "code = pd.read_csv(f'{my_bucket}/data/drugs/sertraline_with_date.csv')\n",
    "code.drug_name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add drug data to df\n",
    "for drug in list_drugs:\n",
    "    code = pd.read_csv(f'{my_bucket}/data/drugs/{drug}_with_date.csv')\n",
    "    code = code[['ID', f'{drug}_DATE', f'{drug}_N']]\n",
    "    df = df.merge(code, left_on = 'ID', right_on = 'ID', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create list of headers drug + DATE\n",
    "codes = []\n",
    "for drug in list_drugs:\n",
    "    a = drug + '_DATE'\n",
    "    codes.append(a)\n",
    "    \n",
    "print(len(codes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep for cox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set variables\n",
    "STUDY_ENDS = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop duplicates\n",
    "df = df.sort_values(by = f'{ndd}_DATE')\n",
    "df = df.drop_duplicates(subset = 'ID', keep = 'first')\n",
    "print(len(df))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create tenure for people with NDD - select folks with an NDD date\n",
    "has_NDD = df[~df[ndd + '_DATE'].isna()]\n",
    "\n",
    "#Calculate the tenure, i.e. the time from the beginning of the study to their time of NDD diagnosis\n",
    "has_NDD['tenure'] = (pd.to_datetime(has_NDD[ndd + '_DATE'], errors = 'coerce') - pd.to_datetime(has_NDD['recruit_date'], errors = 'coerce')).dt.days/365\n",
    "\n",
    "#Only keep people who got NDD after they joined study\n",
    "has_NDD = has_NDD[has_NDD['tenure'] > 0]\n",
    "\n",
    "#Add age_at_tenure to people with an NDD\n",
    "has_NDD['age_at_tenure'] = (pd.to_datetime(has_NDD[ndd + '_DATE'], errors = 'coerce') - pd.to_datetime(has_NDD['date_of_birth'], errors = 'coerce')).dt.days/365\n",
    "\n",
    "#Create tenure for people without NDD - select folks with no NDD date\n",
    "NDD_free = df[df[ndd + '_DATE'].isna()]\n",
    "\n",
    "#For people without NDD, break into dead and alive\n",
    "alive = NDD_free[NDD_free['DATE_OF_DEATH'].isna()]\n",
    "dead = NDD_free[~NDD_free['DATE_OF_DEATH'].isna()]\n",
    "\n",
    "#Calculate the tenure for people who are still alive, i.e. the time from the beginning of the study to the end of study\n",
    "alive['tenure'] = (pd.to_datetime(STUDY_ENDS) - pd.to_datetime(alive['recruit_date'], errors = 'coerce')).dt.days/365\n",
    "\n",
    "#Add age_at_tenure for people who are still alive\n",
    "alive['age_at_tenure'] = (pd.to_datetime(STUDY_ENDS) - pd.to_datetime(alive['date_of_birth'], errors = 'coerce')).dt.days/365\n",
    "\n",
    "#Calculate the tenure for people who are still dead, i.e. the time from the beginning of the study to the end of study\n",
    "dead['tenure'] = (pd.to_datetime(dead['DATE_OF_DEATH']) - pd.to_datetime(dead['recruit_date'])).dt.days/365\n",
    "\n",
    "#Add age_at_tenure for people who are dead\n",
    "dead['age_at_tenure'] = (pd.to_datetime(dead['DATE_OF_DEATH']) - pd.to_datetime(dead['date_of_birth'])).dt.days/365\n",
    "\n",
    "#Combine two groups\n",
    "df = pd.concat([has_NDD, alive, dead])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at df\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encode NDD to 1 or 0\n",
    "df[ndd] = np.where(df[ndd + '_DATE'].isna(), 0, 1)\n",
    "\n",
    "#GENETIC_SEX to 1 or 2\n",
    "df.loc[df.sex_at_birth == 'Female', 'SEX'] = '2'\n",
    "df.loc[df.sex_at_birth == 'Male', 'SEX'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do the high, medium, low analysis\n",
    "new_drug_list = []\n",
    "omit_drug_list = []\n",
    "for code in list_drugs:\n",
    "    df['Lag_' + code] = (pd.to_datetime(df[code + '_DATE'], errors = 'coerce') - pd.to_datetime(df['recruit_date'], errors = 'coerce')).dt.days/365\n",
    "    \n",
    "    quantiles = df[f'{code}_N'].quantile([0.25, 0.5, 0.75])\n",
    "    #print(code)\n",
    "    low = quantiles[0.25]\n",
    "    #print(low)\n",
    "    high = quantiles[0.75]\n",
    "    #print(high)\n",
    "    \n",
    "    df['low_' + code] = np.where((df['Lag_' + code] < df['tenure']) & (df[code + '_N'] <= low), 1, 0)\n",
    "    df['high_' + code] = np.where((df['Lag_' + code] < df['tenure']) & (df[code + '_N'] >= high), 1, 0)\n",
    "    \n",
    "    if high-low > 1:\n",
    "        df['med_' + code] = np.where((df['Lag_' + code] < df['tenure']) & ((df[code + '_N'] > low) & (df[code + '_N'] < high)), 1, 0)\n",
    "        new_drug_list.append(code)\n",
    "    else:\n",
    "        omit_drug_list.append(code)\n",
    "        print(code)\n",
    "        print(low)\n",
    "        print(high)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for standard run and lags\n",
    "for code in list_drugs:\n",
    "    df['Lag_' + code] = (pd.to_datetime(df[code + '_DATE'], errors = 'coerce') - pd.to_datetime(df['recruit_date'], errors = 'coerce')).dt.days/365\n",
    "        \n",
    "    #Select data if it happened before study end -- lag 0\n",
    "    df['QC0_' + code] = np.where((df['Lag_' + code] < df['tenure']), 1, 0)\n",
    "    \n",
    "    #Select data only 10+ years before study end\n",
    "    df['QC10+_' + code] = np.where((df['tenure'] - df['Lag_' + code] > 10), 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(omit_drug_list))\n",
    "print(len(new_drug_list))\n",
    "print(new_drug_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at part of df\n",
    "print(len(df))\n",
    "test = df[['ID', 'SEX', 'age_at_tenure', f'{ndd}_DATE', 'date_of_birth', 'DATE_OF_DEATH','recruit_date', 'tenure', f'{ndd}']]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df to use in cox model\n",
    "df.to_csv(f'{ndd}_with_tenure_{date}.csv', header = True, index = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = df   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = f'{ndd}_with_tenure_{date}.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes that you run setup first\n",
    "\n",
    "# This code lists objects in your Google Bucket\n",
    "\n",
    "# Get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls -r {my_bucket}\", shell=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
