{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook runs the models for Table 3 (high, med, low usage) with and without using APOE as a covariate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Installs\n",
    "!pip install pandas==1.5.3\n",
    "!pip install statsmodels\n",
    "!pip install lifelines==0.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select NDDs\n",
    "ndd_list = ['AD', 'PD', 'DEM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Load list of codes -- see 04_prep_meds_df for how we got this list\n",
    "# Note -- not all drugs have enough data to divide into low, med, high usage, but most do\n",
    "codes = ['diclofenac', 'fluticasone', 'imipramine', 'mirtazapine', 'enalapril', 'terbutaline', 'mirabegron', 'tiotropium', 'temazepam', 'diazepam', 'clomipramine', 'budesonide', 'lisinopril', 'simvastatin', 'celecoxib', 'ciprofloxacin', 'rivastigmine', 'omeprazole', 'dicyclomine', 'etodolac', 'atenolol', 'ranitidine', 'sitagliptin', 'lansoprazole', 'citalopram', 'tamsulosin', 'trazodone', 'prochlorperazine', 'amiodarone', 'trospium', 'escitalopram', 'vardenafil', 'indapamide', 'rabeprazole', 'fludrocortisone', 'gabapentin', 'itraconazole', 'ezetimibe', 'chlordiazepoxide', 'fluvastatin', 'ibuprofen', 'rosiglitazone', 'pioglitazone', 'amphotericin', 'valsartan', 'pravastatin', 'cetirizine', 'salmeterol', 'fluoxetine', 'chlorpromazine', 'risperidone', 'quetiapine', 'tamoxifen', 'oxybutynin', 'tramadol', 'felodipine', 'solifenacin', 'famciclovir', 'paroxetine', 'codeine', 'colchicine', 'fexofenadine', 'erythromycin', 'perindopril', 'digoxin', 'nitrofurantoin', 'tolterodine', 'naproxen', 'spironolactone', 'apixaban', 'clonazepam', 'donepezil', 'oxycodone', 'amantadine', 'methotrexate', 'lactulose', 'amlodipine', 'furosemide', 'carbamazepine', 'metronidazole', 'rasagiline', 'metformin', 'memantine', 'meloxicam', 'pramipexole', 'allopurinol', 'loratadine', 'sumatriptan', 'nifedipine', 'fenofibrate', 'fluconazole', 'buspirone', 'venlafaxine', 'sildenafil', 'dipyridamole', 'loperamide', 'levothyroxine', 'amitriptyline', 'rofecoxib', 'sotalol', 'entacapone', 'lorazepam', 'glimepiride', 'tadalafil', 'bupropion', 'risedronate', 'valproate', 'lamotrigine', 'bumetanide', 'fesoterodine', 'montelukast', 'nortriptyline', 'prednisolone', 'propranolol', 'sulfasalazine', 'insulin', 'indomethacin', 'metoprolol', 'rosuvastatin', 'cimetidine', 'metoclopramide', 'hydroxychloroquine', 'hydroxyzine', 'tetracycline', 'rivaroxaban', 'ramipril', 'verapamil', 'azithromycin', 'galantamine', 'lidocaine', 'diltiazem', 'lithium', 'morphine', 'losartan', 'pantoprazole', 'doxycycline', 'irbesartan', 'levodopa', 'atropine', 'alendronate', 'ofloxacin', 'clopidogrel', 'methocarbamol', 'olanzapine', 'duloxetine', 'eszopiclone', 'warfarin', 'sertraline', 'esomeprazole', 'amoxicillin', 'selegiline', 'finasteride', 'docusate', 'pseudoephedrine', 'aspirin', 'zolpidem', 'ropinirole', 'quinine', 'alfuzosin', 'clonidine', 'doxazosin', 'dutasteride', 'phenytoin', 'candesartan', 'atorvastatin', 'acetaminophen', 'orlistat', 'pregabalin', 'anastrozole', 'levetiracetam', 'bisoprolol', 'baclofen', 'trimethoprim', 'nystatin', 'levocetirizine']\n",
    "print(len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndd_list)\n",
    "print(len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndd_list = ['AD', 'PD', 'DEM']\n",
    "timeline = 'low_med_high'\n",
    "model = 'COX'\n",
    "\n",
    "results = []\n",
    "\n",
    "for ndd in ndd_list:\n",
    "    \n",
    "    #Load df\n",
    "    df = pd.read_csv(f'AoU_{ndd}_with_icd10_with_APOE_MAY_12_2025.csv', parse_dates = True, low_memory = False)\n",
    "    \n",
    "    # Find codes to use so we don't have to use EVERYTHING\n",
    "    codes_with_data = []\n",
    "    lag = 'low'\n",
    "\n",
    "    \n",
    "    for code in codes:\n",
    "        # Choose whether or not to include APOE in analysis here\n",
    "        m = df[['age_at_tenure', 'SEX', 'tenure', ndd, 'low_' + code, 'med_' + code, 'high_' + code, 'QC0_A04', 'QC0_B02', 'QC0_B37', 'QC0_E10', 'QC0_E11', 'QC0_E27', 'QC0_E78', 'QC0_E87', 'QC0_F20', 'QC0_F31', 'QC0_F32', 'QC0_F33', 'QC0_F40', 'QC0_F41', 'QC0_F42', 'QC0_F43', 'QC0_F44', 'QC0_F45', 'QC0_F48', 'QC0_F50', 'QC0_F51', 'QC0_G40', 'QC0_G43', 'QC0_G47', 'QC0_H66', 'QC0_I10', 'QC0_I11', 'QC0_I12', 'QC0_I15', 'QC0_I20', 'QC0_I21', 'QC0_I25', 'QC0_I47', 'QC0_I48', 'QC0_I49', 'QC0_I50', 'QC0_I60', 'QC0_I61', 'QC0_I62', 'QC0_I63', 'QC0_I65', 'QC0_I66', 'QC0_I67', 'QC0_I69', 'QC0_I82', 'QC0_K04', 'QC0_K05', 'QC0_K20', 'QC0_K21', 'QC0_K22', 'QC0_K25', 'QC0_K31', 'QC0_K51', 'QC0_K59', 'QC0_K70', 'QC0_K71', 'QC0_K72', 'QC0_K73', 'QC0_K74', 'QC0_K75', 'QC0_K76', 'QC0_L25', 'QC0_L40', 'QC0_L50', 'QC0_M06', 'QC0_M13', 'QC0_M15', 'QC0_M16', 'QC0_M17', 'QC0_M18', 'QC0_M19', 'QC0_M32', 'QC0_M45', 'QC0_M79', 'QC0_M80', 'QC0_M81', 'QC0_M88', 'QC0_N04', 'QC0_N10', 'QC0_N18', 'QC0_N19', 'QC0_N30', 'QC0_N31', 'QC0_N32', 'QC0_N39', 'QC0_N40', 'QC0_N94']]\n",
    "        #m = df[['age_at_tenure', 'SEX', 'tenure', ndd, 'low_' + code, 'med_' + code, 'high_' + code, 'QC0_A04', 'QC0_B02', 'QC0_B37', 'QC0_E10', 'QC0_E11', 'QC0_E27', 'QC0_E78', 'QC0_E87', 'QC0_F20', 'QC0_F31', 'QC0_F32', 'QC0_F33', 'QC0_F40', 'QC0_F41', 'QC0_F42', 'QC0_F43', 'QC0_F44', 'QC0_F45', 'QC0_F48', 'QC0_F50', 'QC0_F51', 'QC0_G40', 'QC0_G43', 'QC0_G47', 'QC0_H66', 'QC0_I10', 'QC0_I11', 'QC0_I12', 'QC0_I15', 'QC0_I20', 'QC0_I21', 'QC0_I25', 'QC0_I47', 'QC0_I48', 'QC0_I49', 'QC0_I50', 'QC0_I60', 'QC0_I61', 'QC0_I62', 'QC0_I63', 'QC0_I65', 'QC0_I66', 'QC0_I67', 'QC0_I69', 'QC0_I82', 'QC0_K04', 'QC0_K05', 'QC0_K20', 'QC0_K21', 'QC0_K22', 'QC0_K25', 'QC0_K31', 'QC0_K51', 'QC0_K59', 'QC0_K70', 'QC0_K71', 'QC0_K72', 'QC0_K73', 'QC0_K74', 'QC0_K75', 'QC0_K76', 'QC0_L25', 'QC0_L40', 'QC0_L50', 'QC0_M06', 'QC0_M13', 'QC0_M15', 'QC0_M16', 'QC0_M17', 'QC0_M18', 'QC0_M19', 'QC0_M32', 'QC0_M45', 'QC0_M79', 'QC0_M80', 'QC0_M81', 'QC0_M88', 'QC0_N04', 'QC0_N10', 'QC0_N18', 'QC0_N19', 'QC0_N30', 'QC0_N31', 'QC0_N32', 'QC0_N39', 'QC0_N40', 'QC0_N94', 'e3/e4', 'e4/e4']]\n",
    "        \n",
    "        n=sum(m[f'{lag}_'+ code])\n",
    "        df_pair = m[m[f'{lag}_'+ code]==1]\n",
    "        n_pairs = sum(df_pair[ndd])\n",
    "        if n == 0:\n",
    "            pass\n",
    "        elif n_pairs < 5:\n",
    "            pass\n",
    "        elif n == n_pairs:\n",
    "            pass\n",
    "        else:\n",
    "            print(code)\n",
    "            codes_with_data.append(code)\n",
    "    \n",
    "    print(ndd)\n",
    "    print(len(codes_with_data))\n",
    "    \n",
    "    for code in codes_with_data:\n",
    "\n",
    "        # Choose whether or not to include APOE in analysis here\n",
    "        m = df[['age_at_tenure', 'SEX', 'tenure', ndd, 'low_' + code, 'med_' + code, 'high_' + code, 'QC0_A04', 'QC0_B02', 'QC0_B37', 'QC0_E10', 'QC0_E11', 'QC0_E27', 'QC0_E78', 'QC0_E87', 'QC0_F20', 'QC0_F31', 'QC0_F32', 'QC0_F33', 'QC0_F40', 'QC0_F41', 'QC0_F42', 'QC0_F43', 'QC0_F44', 'QC0_F45', 'QC0_F48', 'QC0_F50', 'QC0_F51', 'QC0_G40', 'QC0_G43', 'QC0_G47', 'QC0_H66', 'QC0_I10', 'QC0_I11', 'QC0_I12', 'QC0_I15', 'QC0_I20', 'QC0_I21', 'QC0_I25', 'QC0_I47', 'QC0_I48', 'QC0_I49', 'QC0_I50', 'QC0_I60', 'QC0_I61', 'QC0_I62', 'QC0_I63', 'QC0_I65', 'QC0_I66', 'QC0_I67', 'QC0_I69', 'QC0_I82', 'QC0_K04', 'QC0_K05', 'QC0_K20', 'QC0_K21', 'QC0_K22', 'QC0_K25', 'QC0_K31', 'QC0_K51', 'QC0_K59', 'QC0_K70', 'QC0_K71', 'QC0_K72', 'QC0_K73', 'QC0_K74', 'QC0_K75', 'QC0_K76', 'QC0_L25', 'QC0_L40', 'QC0_L50', 'QC0_M06', 'QC0_M13', 'QC0_M15', 'QC0_M16', 'QC0_M17', 'QC0_M18', 'QC0_M19', 'QC0_M32', 'QC0_M45', 'QC0_M79', 'QC0_M80', 'QC0_M81', 'QC0_M88', 'QC0_N04', 'QC0_N10', 'QC0_N18', 'QC0_N19', 'QC0_N30', 'QC0_N31', 'QC0_N32', 'QC0_N39', 'QC0_N40', 'QC0_N94']]\n",
    "        #m = df[['age_at_tenure', 'SEX', 'tenure', ndd, 'low_' + code, 'med_' + code, 'high_' + code, 'QC0_A04', 'QC0_B02', 'QC0_B37', 'QC0_E10', 'QC0_E11', 'QC0_E27', 'QC0_E78', 'QC0_E87', 'QC0_F20', 'QC0_F31', 'QC0_F32', 'QC0_F33', 'QC0_F40', 'QC0_F41', 'QC0_F42', 'QC0_F43', 'QC0_F44', 'QC0_F45', 'QC0_F48', 'QC0_F50', 'QC0_F51', 'QC0_G40', 'QC0_G43', 'QC0_G47', 'QC0_H66', 'QC0_I10', 'QC0_I11', 'QC0_I12', 'QC0_I15', 'QC0_I20', 'QC0_I21', 'QC0_I25', 'QC0_I47', 'QC0_I48', 'QC0_I49', 'QC0_I50', 'QC0_I60', 'QC0_I61', 'QC0_I62', 'QC0_I63', 'QC0_I65', 'QC0_I66', 'QC0_I67', 'QC0_I69', 'QC0_I82', 'QC0_K04', 'QC0_K05', 'QC0_K20', 'QC0_K21', 'QC0_K22', 'QC0_K25', 'QC0_K31', 'QC0_K51', 'QC0_K59', 'QC0_K70', 'QC0_K71', 'QC0_K72', 'QC0_K73', 'QC0_K74', 'QC0_K75', 'QC0_K76', 'QC0_L25', 'QC0_L40', 'QC0_L50', 'QC0_M06', 'QC0_M13', 'QC0_M15', 'QC0_M16', 'QC0_M17', 'QC0_M18', 'QC0_M19', 'QC0_M32', 'QC0_M45', 'QC0_M79', 'QC0_M80', 'QC0_M81', 'QC0_M88', 'QC0_N04', 'QC0_N10', 'QC0_N18', 'QC0_N19', 'QC0_N30', 'QC0_N31', 'QC0_N32', 'QC0_N39', 'QC0_N40', 'QC0_N94', 'e3/e4', 'e4/e4']]\n",
    "  \n",
    "        cph = CoxPHFitter()\n",
    "        cph.fit(m, duration_col = 'tenure', event_col = ndd, show_progress=False, step_size = 0.001)\n",
    "        #cph.print_summary()\n",
    "        #cph.plot()\n",
    "        \n",
    "        actual_p = cph._compute_p_values()\n",
    "        results_df = cph.summary\n",
    "        \n",
    "        results_df = results_df.reset_index()\n",
    "        test2 = results_df.iloc[2]\n",
    "        test3 = results_df.iloc[3]\n",
    "        test4 = results_df.iloc[4]\n",
    "        \n",
    "\n",
    "        covariate = code\n",
    "        \n",
    "        HR2 = test2['exp(coef)']\n",
    "        ci_min2 = test2['exp(coef) lower 95%']\n",
    "        ci_max2 = test2['exp(coef) upper 95%']\n",
    "        p2 = actual_p[2]\n",
    "        \n",
    "        HR3 = test3['exp(coef)']\n",
    "        ci_min3 = test3['exp(coef) lower 95%']\n",
    "        ci_max3 = test3['exp(coef) upper 95%']\n",
    "        p3 = actual_p[3]\n",
    "        \n",
    "        HR4 = test4['exp(coef)']\n",
    "        ci_min4 = test4['exp(coef) lower 95%']\n",
    "        ci_max4 = test4['exp(coef) upper 95%']\n",
    "        p4 = actual_p[4]\n",
    "        \n",
    "        n2=sum(m[f'low_'+ code])\n",
    "        df_pair2 = m[m[f'low_'+ code]==1]\n",
    "        n_pairs2 = sum(df_pair2[ndd])\n",
    "        \n",
    "        n3=sum(m[f'med_'+ code])\n",
    "        df_pair3 = m[m[f'med_'+ code]==1]\n",
    "        n_pairs3 = sum(df_pair3[ndd])\n",
    "        #print(n3, n_pairs3)\n",
    "\n",
    "        n4=sum(m[f'high_'+ code])\n",
    "        df_pair4 = m[m[f'high_'+ code]==1]\n",
    "        n_pairs4 = sum(df_pair4[ndd])\n",
    "        #print(n4, n_pairs4)\n",
    "\n",
    "\n",
    "        print(covariate, ndd, HR2, ci_min2, ci_max2, p2, n2, n_pairs2)\n",
    "        print(covariate, ndd, HR3, ci_min3, ci_max3, p3, n3, n_pairs3)\n",
    "        print(covariate, ndd, HR4, ci_min4, ci_max4, p4, n4, n_pairs4)\n",
    "        \n",
    "        results.append((covariate, ndd, model, timeline, 'low', HR2, ci_min2, ci_max2, p2, n_pairs2, n2))\n",
    "        results.append((covariate, ndd, model, timeline, 'med', HR3, ci_min3, ci_max3, p3, n_pairs3, n3))\n",
    "        results.append((covariate, ndd, model, timeline, 'high', HR4, ci_min4, ci_max4, p4, n_pairs4, n4))\n",
    "            \n",
    "cox1 = pd.DataFrame(results, columns=('PRIOR','OUTCOME', 'MODEL','TIMELINE', 'LAG', 'HR', 'ci_min', \"ci_max\", 'P_VAL', 'N_pairs', 'N'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine results\n",
    "output = pd.concat([cox1])\n",
    "\n",
    "#Adding FDR Correction\n",
    "\n",
    "#Sort P-values\n",
    "output = output.sort_values(by = \"P_VAL\")\n",
    "\n",
    "#Drop Nan-values\n",
    "output = output.dropna()\n",
    "\n",
    "#FDR Correction\n",
    "rejected, p_corr = fdrcorrection(output['P_VAL'], is_sorted=True)\n",
    "output['P_CORR'] = p_corr\n",
    "output['SIGNIFICANT'] = rejected\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 'MAY_14_2025'\n",
    "output.to_csv(f'AoU_{date}_results_high_low_with_ICD10.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = output   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = f'AoU_{date}_results_high_low_with_ICD10.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/results/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
