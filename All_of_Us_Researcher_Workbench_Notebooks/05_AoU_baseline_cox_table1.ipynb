{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# installs\n",
    "!pip install --upgrade pip\n",
    "!pip install pandas==1.5.3\n",
    "!pip install statsmodels\n",
    "!pip install lifelines==0.26.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports here.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "from lifelines import CoxPHFitter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load one df to test\n",
    "ndd = 'PD'\n",
    "df = pd.read_csv(f'{ndd}_with_tenure_MAY_05_2025.csv', parse_dates = True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select NDDs\n",
    "ndd_list = ['AD', 'PD', 'DEM']\n",
    "\n",
    "#Load list of codes\n",
    "meds2 = pd.read_csv('meds_with_cleaned_name_MAY_05_2025.csv')\n",
    "codes = list(set(list(meds2['cleaned_med'])))\n",
    "print(len(codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(ndd_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeline = 'ever taken'\n",
    "model = 'COX'\n",
    "lag = \"0\"\n",
    "\n",
    "results = []\n",
    "\n",
    "for ndd in ndd_list:\n",
    "    \n",
    "    #Load df\n",
    "    df = pd.read_csv(f'{ndd}_with_tenure_MAY_05_2025.csv', parse_dates = True)\n",
    "    \n",
    "    # Find codes to use so we don't have to use EVERYTHING\n",
    "    codes_with_data = []\n",
    "    lag = '0'\n",
    "\n",
    "    for code in codes:\n",
    "        m = df[['age_at_tenure', 'SEX', 'tenure', ndd, f'QC{lag}_' + code]]\n",
    "        n=sum(m[f'QC{lag}_'+ code])\n",
    "        df_pair = m[m[f'QC{lag}_'+ code]==1]\n",
    "        n_pairs = sum(df_pair[ndd])\n",
    "        if n == 0:\n",
    "            pass\n",
    "        elif n_pairs < 10:\n",
    "            pass\n",
    "        elif n == n_pairs:\n",
    "            pass\n",
    "        else:\n",
    "            print(code)\n",
    "            codes_with_data.append(code)\n",
    "    \n",
    "    print(ndd)\n",
    "    print(len(codes_with_data))\n",
    "    \n",
    "    for code in codes_with_data:\n",
    "        \n",
    "        m = df[['age_at_tenure', 'SEX', 'tenure', ndd, f'QC{lag}_' + code]]\n",
    "        n=sum(m[f'QC{lag}_'+ code])\n",
    "        df_pair = m[m[f'QC{lag}_'+ code]==1]\n",
    "        n_pairs = sum(df_pair[ndd])\n",
    "        \n",
    "        cph = CoxPHFitter()\n",
    "        cph.fit(m, duration_col = 'tenure', event_col = ndd, show_progress=False, step_size = 0.01)\n",
    "        #cph.print_summary()\n",
    "        #cph.plot()\n",
    "        \n",
    "        actual_p = cph._compute_p_values()\n",
    "        results_df = cph.summary\n",
    "        results_df = results_df.reset_index()\n",
    "        test = results_df.iloc[2]\n",
    "\n",
    "        covariate = code\n",
    "        HR = test['exp(coef)']\n",
    "        ci_min = test['exp(coef) lower 95%']\n",
    "        ci_max = test['exp(coef) upper 95%']\n",
    "        p = actual_p[2]\n",
    "\n",
    "        print(covariate, ndd, HR, ci_min, ci_max, p, n_pairs, n)\n",
    "        results.append((covariate, ndd, model, timeline, lag, HR, ci_min, ci_max, p, n_pairs, n))\n",
    "            \n",
    "cox1 = pd.DataFrame(results, columns=('PRIOR','OUTCOME', 'MODEL','TIMELINE', 'LAG', 'HR', 'ci_min', \"ci_max\", 'P_VAL', \"N_pairs\", \"N\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine results\n",
    "output = pd.concat([cox1])\n",
    "\n",
    "#Adding FDR Correction\n",
    "\n",
    "#Sort P-values\n",
    "output = output.sort_values(by = \"P_VAL\")\n",
    "\n",
    "#Drop Nan-values\n",
    "output = output.dropna()\n",
    "\n",
    "#FDR Correction\n",
    "rejected, p_corr = fdrcorrection(output['P_VAL'], is_sorted=True)\n",
    "output['P_CORR'] = p_corr\n",
    "output['SIGNIFICANT'] = rejected\n",
    "\n",
    "output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date = 'MAY_05_2025'\n",
    "output.to_csv(f'AoU_{date}_results_lag_zero.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = output   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = f'AoU_{date}_results_lag_zero.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes that you run setup first\n",
    "\n",
    "# This code lists objects in your Google Bucket\n",
    "\n",
    "# Get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# List objects in the bucket\n",
    "print(subprocess.check_output(f\"gsutil ls -r {my_bucket}\", shell=True).decode('utf-8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
