{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prep df for cox adding ICD10 codes and APOE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "icd10_codes = ['A04', 'B02', 'B37', 'E10', 'E11', 'E27', 'E78', 'E87', 'F20', 'F31', 'F32', 'F33', 'F40', 'F41', 'F42', 'F43', 'F44', 'F45', 'F48', 'F50', 'F51', 'G40', 'G43', 'G47', 'H66', 'I10', 'I11', 'I12', 'I15', 'I20', 'I21', 'I25', 'I47', 'I48', 'I49', 'I50', 'I60', 'I61', 'I62', 'I63', 'I65', 'I66', 'I67', 'I69', 'I82', 'K04', 'K05', 'K20', 'K21', 'K22', 'K25', 'K31', 'K51', 'K59', 'K70', 'K71', 'K72', 'K73', 'K74', 'K75', 'K76', 'L25', 'L40', 'L50', 'M06', 'M13', 'M15', 'M16', 'M17', 'M18', 'M19', 'M32', 'M45', 'M79', 'M80', 'M81', 'M88', 'N04', 'N10', 'N18', 'N19', 'N30', 'N31', 'N32', 'N39', 'N40', 'N94']\n",
    "print(len(icd10_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in icd10_codes:\n",
    "    df = pd.read_csv(f'{code}_with_date.csv')\n",
    "    df = df.rename(columns = {'condition_start_datetime':code, 'person_id':'ID'})\n",
    "        \n",
    "    #remove duplicate IDs, keeping the first condition\n",
    "    df = df.sort_values(by = code)\n",
    "    df = df.drop_duplicates(subset = 'ID', keep = 'first')\n",
    "    df = df[['ID', code]]\n",
    "    df.to_csv(f'{code}_with_date_dup_dropped.csv', header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check one ICD10 code\n",
    "test = pd.read_csv(f'{code}_with_date_dup_dropped.csv')\n",
    "test = test.sort_values(by = code)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to make sure only first ID per code is still included\n",
    "test.ID.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add covariates to original dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load df -- we did this for all NDDs: AD, PD, and DEM\n",
    "\n",
    "ndd = 'PD'\n",
    "df = pd.read_csv(f'{ndd}_with_tenure_MAY_05_2025.csv', low_memory = False)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(icd10_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for code in icd10_codes:\n",
    "    c = pd.read_csv(f'{code}_with_date_dup_dropped.csv')\n",
    "    c = c[['ID', code]]\n",
    "    df = df.merge(c, left_on = 'ID', right_on = 'ID', how = 'left')\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check to see counts\n",
    "for condition in icd10_codes:\n",
    "    print(condition)\n",
    "    print(df[f'{condition}'].isna().value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We only want to include an ICD10 code as a covariate if it was recorded BEFORE the end of the study\n",
    "for code in icd10_codes:\n",
    "    df['Lag_' + code] = (pd.to_datetime(df[code], errors = 'coerce') - pd.to_datetime(df['recruit_date'])).dt.days/365\n",
    "        \n",
    "    #Select data if it happened before study end -- lag 0\n",
    "    df['QC0_' + code] = np.where((df['Lag_' + code] < df['tenure']), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add APOE status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load APOE file created in 06_AoU_pull_APOE_status_V8.ipynb\n",
    "apoe = pd.read_csv('apoe_for_meds_FEB_2025.csv')\n",
    "apoe = apoe[['IID', 'APOE_GENOTYPE']]\n",
    "apoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with df created above\n",
    "df = df.merge(apoe, left_on = 'ID', right_on = 'IID', how = 'left')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the counts\n",
    "df.APOE_GENOTYPE.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove samples with no APOE data\n",
    "df = df[~df['APOE_GENOTYPE'].isna()]\n",
    "\n",
    "#Remove samples with unknown\n",
    "df = df[df['APOE_GENOTYPE'] != 'unknown']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check value_counts for APOE\n",
    "df.APOE_GENOTYPE.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the 'APOE_GENOTYPE' column\n",
    "df_encoded = pd.get_dummies(df, columns=['APOE_GENOTYPE'], prefix='', prefix_sep='')\n",
    "\n",
    "# Display the result\n",
    "df_encoded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at df\n",
    "df_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save file\n",
    "df_encoded.to_csv(f'AoU_{ndd}_with_icd10_with_APOE_MAY_12_2025.csv', header = True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = df_encoded   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "#destination_filename = f'AoU_{ndd}_with_icd10_MAY_05_2025.csv'\n",
    "destination_filename = f'AoU_{ndd}_with_icd10_with_APOE_MAY_12_2025.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This snippet assumes you run setup first\n",
    "\n",
    "# # This code copies file in your Google Bucket and loads it into a dataframe\n",
    "\n",
    "# # Replace 'test.csv' with THE NAME of the file you're going to download from the bucket (don't delete the quotation marks)\n",
    "# name_of_file_in_bucket = 'apoe_for_meds_FEB_2025.csv'\n",
    "\n",
    "# ########################################################################\n",
    "# ##\n",
    "# ################# DON'T CHANGE FROM HERE ###############################\n",
    "# ##\n",
    "# ########################################################################\n",
    "\n",
    "# # get the bucket name\n",
    "# my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# # copy csv file from the bucket to the current working space\n",
    "# os.system(f\"gsutil cp '{my_bucket}/data/{name_of_file_in_bucket}' .\")\n",
    "\n",
    "# print(f'[INFO] {name_of_file_in_bucket} is successfully downloaded into your working space')\n",
    "# # save dataframe in a csv file in the same workspace as the notebook\n",
    "# my_dataframe = pd.read_csv(name_of_file_in_bucket)\n",
    "# my_dataframe.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
