{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.now()\n",
    "bucket = os.getenv(\"WORKSPACE_BUCKET\")\n",
    "bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hail as hl\n",
    "hl.default_reference(new_default_reference = \"GRCh38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_wgs_path = os.getenv(\"WGS_ACAF_THRESHOLD_SPLIT_HAIL_PATH\")\n",
    "mt_wgs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hardcode the path in case you are not in a v8 workspace\n",
    "# mt_wgs_path = \"gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/multiMT/hail.mt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt = hl.read_matrix_table(mt_wgs_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt_array_path = os.getenv(\"MICROARRAY_HAIL_STORAGE_PATH\")\n",
    "mt_array_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mt2 = hl.read_matrix_table(mt_array_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WGS\n",
    "mt.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Array\n",
    "mt2.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intervals = ['chr19:44908684-44908685', 'chr19:44908821-44908823']\n",
    "\n",
    "filt_mt = hl.filter_intervals(mt, [hl.parse_locus_interval(x, reference_genome='GRCh38') for x in intervals])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_mt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi = filt_mt.filter_rows(hl.len(filt_mt.alleles) == 2)\n",
    "bi = bi.annotate_rows(a_index=1, was_split=False)\n",
    "multi = filt_mt.filter_rows(hl.len(filt_mt.alleles) > 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split = hl.split_multi_hts(multi,\n",
    "                               keep_star=False,\n",
    "                               left_aligned=False,\n",
    "                               vep_root='vep',\n",
    "                               permit_shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_mt = split.union_rows(bi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt_mt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_path = f'{bucket}/data/test_plink'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hl.export_plink(filt_mt, out_path, ind_id = filt_mt.s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir plink_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp '{bucket}/data/test_plink*' plink_files/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head plink_files/test_plink.bim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! cat plink_files/test_plink.fam | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!plink --bfile plink_files/test_plink --snps chr19:44908684:T:C,chr19:44908822:C:T --make-bed --out plink_files/apoe_snps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!plink --bfile plink_files/apoe_snps --recode compound-genotypes --out plink_files/apoe_snps_recode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile APOE_genotypes_PLINK_ped.py\n",
    "#!/bin/env python\n",
    "\n",
    "# Determine APOE genotypes from PLINK output\n",
    "    # January 2021\n",
    "    # Mary B. Makarious, Makayla Portley, and Cornelis Blauwendraat (LNG/NIA/NINDS/NIH)\n",
    "    # Script usage:\n",
    "        # python APOE_genotypes_PLINK_ped.py -i INPUT.ped -o OUTPUT_NAME\n",
    "\n",
    "## APOE Information\n",
    "# https://www.snpedia.com/index.php/APOE\n",
    "\n",
    "    # |          APOE GENO         \t| rs429358 \t| rs7412 \t|             COMBINED             \t|\n",
    "    # |:--------------------------:\t|:--------:\t|:------:\t|:--------------------------------:\t|\n",
    "    # |            e1/e1           \t|    CC    \t|   TT   \t|               CC_TT              \t|\n",
    "    # |            e1/e2           \t|    CT    \t|   TT   \t|          CT_TT or TC_TT          \t|\n",
    "    # |            e1/e4           \t|    CC    \t|   CT   \t|          CC_CT or CC_TC          \t|\n",
    "    # |            e2/e2           \t|    TT    \t|   TT   \t|               TT_TT              \t|\n",
    "    # |            e2/e3           \t|    TT    \t|   TC   \t|          TT_TC or TT_CT          \t|\n",
    "    # | e2/e4 or e1/e3 (Ambiguous) \t|    TC    \t|   TC   \t| TC_TC or CT_CT or TC_CT or CT_TC \t|\n",
    "    # |            e3/e3           \t|    TT    \t|   CC   \t|               TT_CC              \t|\n",
    "    # |            e3/e4           \t|    TC    \t|   CC   \t|          TC_CC or CT_CC          \t|\n",
    "    # |            e4/e4           \t|    CC    \t|   CC   \t|               CC_CC              \t|\n",
    "\n",
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from functools import reduce\n",
    "import argparse\n",
    "\n",
    "# Initialize parser and add arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--input\", \"-i\", help=\"Input file name (with suffix)\")\n",
    "parser.add_argument(\"--output\", \"-o\", help=\"Desired output name (without suffix)\")\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Read in the .ped file and force column names\n",
    "header_text = [\"FID\", \"IID\", \"PAT\", \"MAT\", \"SEX\", \"PHENO\", \"rs429358\", \"rs7412\"]\n",
    "input_ped_df = pd.read_csv(args.input, sep = \" \", header=None, names=header_text)\n",
    "\n",
    "# Make a combined column, gluing the genotypes from the rs429358 and rs7412 columns\n",
    "input_ped_df['rs429358_rs7412'] = input_ped_df['rs429358'].astype(str)+'_'+input_ped_df['rs7412']\n",
    "\n",
    "# Initialize a dictionary with the genotypes to search what genotype the alleles generate\n",
    "apoe_genotypes_dict = {\n",
    "    'CC_TT' : 'e1/e1',\n",
    "    'CT_TT' : 'e1/e2',\n",
    "    'TC_TT' : 'e1/e2',\n",
    "    'CC_CT' : 'e1/e4',\n",
    "    'CC_TC' : 'e1/e4',\n",
    "    'TT_TT' : 'e2/e2',\n",
    "    'TT_TC' : 'e2/e3',\n",
    "    'TT_CT' : 'e2/e3',\n",
    "    'TC_TC' : 'e2/e4 or e1/e3',\n",
    "    'CT_CT' : 'e2/e4 or e1/e3',\n",
    "    'TC_CT' : 'e2/e4 or e1/e3',\n",
    "    'CT_TC' : 'e2/e4 or e1/e3',\n",
    "    'TT_CC' : 'e3/e3',\n",
    "    'TC_CC' : 'e3/e4',\n",
    "    'CT_CC' : 'e3/e4',\n",
    "    'CC_CC' : 'e4/e4'\n",
    "}\n",
    "\n",
    "# Map the combined column to the dictionary to extract the genotypes\n",
    "input_ped_df['APOE_GENOTYPE'] = input_ped_df['rs429358_rs7412'].map(apoe_genotypes_dict)\n",
    "\n",
    "# If any of the combined alleles weren't in the dictionary, the dataframe now has NaN values\n",
    "# This happens if you have a 0 or missingness somewhere, resulting in an unsure genotype call\n",
    "# Replace these with something more useful, and state the APOE genotype as \"unknown\"\n",
    "input_ped_df.replace(np.nan, 'unknown', regex=True, inplace=True)\n",
    "\n",
    "# Make a file of just the FID, IID, SEX, PHENO, and APOE genotype\n",
    "subset_geno_df = input_ped_df.drop(columns=['PAT', 'MAT', 'rs429358', 'rs7412'])\n",
    "\n",
    "## Generate counts\n",
    "# Generate APOE genotype counts and percentages for entire dataset\n",
    "counts_df = pd.DataFrame(subset_geno_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "counts_df.columns = ['APOE_GENOTYPE', 'TOTAL_COUNT']\n",
    "counts_df['TOTAL_PERCENT'] = counts_df['TOTAL_COUNT'] / subset_geno_df.shape[0] * 100\n",
    "\n",
    "# Separate out into cases, controls, and missing phenotypes\n",
    "    # This assumes controls=1 and cases=2 (missing is -9)\n",
    "\n",
    "# Subset by phenotype\n",
    "missing_pheno_df = subset_geno_df[subset_geno_df['PHENO'] == -9]\n",
    "controls_df = subset_geno_df[subset_geno_df['PHENO'] == 1]\n",
    "cases_df = subset_geno_df[subset_geno_df['PHENO'] == 2]\n",
    "\n",
    "# Generate APOE genotype counts and percentages for missing phenotypes\n",
    "missing_pheno_counts_df = pd.DataFrame(missing_pheno_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "missing_pheno_counts_df.columns = ['APOE_GENOTYPE', 'MISSING_PHENO_COUNT']\n",
    "missing_pheno_counts_df['MISSING_PHENO_PERCENT'] = missing_pheno_counts_df['MISSING_PHENO_COUNT'] / missing_pheno_df.shape[0] * 100\n",
    "\n",
    "# Generate APOE genotype counts and percentages for controls\n",
    "controls_counts_df = pd.DataFrame(controls_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "controls_counts_df.columns = ['APOE_GENOTYPE', 'CONTROLS_COUNT']\n",
    "controls_counts_df['CONTROLS_PERCENT'] = controls_counts_df['CONTROLS_COUNT'] / controls_df.shape[0] * 100\n",
    "\n",
    "# Generate APOE genotype counts and percentages for cases\n",
    "cases_counts_df = pd.DataFrame(cases_df['APOE_GENOTYPE'].value_counts().reset_index())\n",
    "cases_counts_df.columns = ['APOE_GENOTYPE', 'CASES_COUNT']\n",
    "cases_counts_df['CASES_PERCENT'] = cases_counts_df['CASES_COUNT'] / cases_df.shape[0] * 100\n",
    "\n",
    "# Merge the dataframes together for final summary counts file\n",
    "dataframes_tomerge = [counts_df, missing_pheno_counts_df, controls_counts_df, cases_counts_df]\n",
    "merged_summary_df = reduce(lambda left,right: pd.merge(left,right,on='APOE_GENOTYPE'), dataframes_tomerge)\n",
    "\n",
    "## Export\n",
    "complete_df_output = args.output + \".APOE_GENOTYPES.csv\"\n",
    "counts_df_output = args.output + \".APOE_SUMMARY.csv\"\n",
    "\n",
    "# Save out the complete dataframe as a .csv\n",
    "print(f\"Your complete genotype file has been saved here: {complete_df_output}\")\n",
    "subset_geno_df.to_csv(complete_df_output, index=False)\n",
    "\n",
    "# Save out the counts as a .csv\n",
    "print(f\"The summary counts have been saved here: {counts_df_output}\")\n",
    "merged_summary_df.to_csv(counts_df_output, index=False)\n",
    "\n",
    "# Done!\n",
    "print(\"Thanks!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "python APOE_genotypes_PLINK_ped.py -i plink_files/apoe_snps_recode.ped -o plink_files/apoe_snps_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apoe = pd.read_csv('plink_files/apoe_snps_test.APOE_GENOTYPES.csv')\n",
    "apoe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apoe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apoe.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet assumes you run setup first\n",
    "\n",
    "# This code saves your dataframe into a csv file in a \"data\" folder in Google Bucket\n",
    "\n",
    "# Replace df with THE NAME OF YOUR DATAFRAME\n",
    "my_dataframe = apoe   \n",
    "\n",
    "# Replace 'test.csv' with THE NAME of the file you're going to store in the bucket (don't delete the quotation marks)\n",
    "destination_filename = 'apoe_for_meds_JAN_2025.csv'\n",
    "\n",
    "########################################################################\n",
    "##\n",
    "################# DON'T CHANGE FROM HERE ###############################\n",
    "##\n",
    "########################################################################\n",
    "\n",
    "# save dataframe in a csv file in the same workspace as the notebook\n",
    "my_dataframe.to_csv(destination_filename, index=False)\n",
    "\n",
    "# get the bucket name\n",
    "my_bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "\n",
    "# copy csv file to the bucket\n",
    "args = [\"gsutil\", \"cp\", f\"./{destination_filename}\", f\"{my_bucket}/data/\"]\n",
    "output = subprocess.run(args, capture_output=True)\n",
    "\n",
    "# print output from gsutil\n",
    "output.stderr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
